# Dimensions underlying the representational alignment of deep neural networks with humans
- **Published**: [2024 Conference on Computer Vision]
- **Link**: https://arxiv.org/abs/2406.19087
- **Summary**: The paper analyzes representational alignment between humans and DNNs, highlighting divergent strategies.

### Problem
- Differences between human and DNN representations.
  - DNNs prioritize visual features over semantic ones.
  - Humans use semantic features dominantly.
  - Challenges in achieving representational alignment.

### Contributions
- Framework for comparing human and DNN representations.
- Analysis of visual vs. semantic feature dominance.
- Insights into representational strategies of DNNs.

### Method
- Used a triplet odd-one-out task to compare representations.
  - Github: [https://github.com/florianmahner/object-dimensions](https://github.com/florianmahner/object-dimensions)
- Dataset: Human similarity judgments and VGG-16 DNN embeddings.

### Result
- DNNs emphasize visual features.
- Humans emphasize semantic features.
- Significant misalignment in representations.
- "By making representations directly comparable, our results reveal important challenges for representational alignment, offering a means for improving their comparability."

### Conclusion
- DNNs and humans use different representational strategies, impacting alignment.

### Reference
- Mahner, F. P., Muttenthaler, L., et al. (2024). Dimensions underlying the representational alignment of deep neural networks with humans.

- ![img](DNN_Humans_Alignment.png)
