# Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies
- **Published**: FAccT '23
- **Link**: https://arxiv.org/abs/2112.11471
- **Summary**: This survey reviews over 100 empirical studies to understand and improve human-AI decision-making, emphasizing the need for unified research frameworks.
- Presentation: https://www.youtube.com/watch?v=Lk8n6Aqp75I
- list of papers they studied: https://haidecisionmaking.github.io/
  
  

### Problem 
- **Integration of AI in High-Stakes Domains**: Challenges in sensitive sectors like healthcare.
- **Lack of Coherent Practices**: The absence of uniform practices hinders scientific progress.
- **Diverse Methodologies and Disciplines**: Varied approaches complicate generalization of findings.
- **Need for Common Frameworks**: Essential for understanding AI's impact on decisions.
- **Early Development of Methodologies**: Evaluation metrics and methodologies still developing.


### Contributions
- **Survey of Over 100 Papers**: Analysis of study design choices across different domains to evaluate AI's role in human decision-making.
- **Identification of Gaps**: Highlights the disparate methodologies and the need for standardized frameworks in human-AI decision-making research.
- **Recommendations for Future Research**: Proposes directions for developing common frameworks and methodologies to advance the empirical science of human-AI decision-making.

### Method
- **Focus on empirical human-subject studies**: Evaluates human performance and AI interaction.
- **Inclusion criteria**: Includes evaluative studies, excludes formative and non-decision tasks.
- **Targeted tasks**: Must involve human decision-makers, not AI automation or developers.
- **Search Strategy**: Reviewed proceedings from premier AI and HCI conferences, 2018-2021.
- **Initial search outcome**: Over 130 papers identified, narrowed down to over 80 relevant papers.
- **Coding process**: Authors coded papers for decision tasks, AI models, and metrics.
- **Grouping and consensus**: Authors met regularly to discuss and finalize coding categories.


### Result

-  Current Trends on how AI models and assistance elements are used and studied
   - (1) Limited uses of deep learning models
   - (2) Assistance beyond predictions
   - (3) A focus on AI explanations
   - (4) Beyond the model

- Gaps in Current Practices
   - (1) Fragmented understanding and limited design space of AI assistance elements
   - (2) Focus on decision trials only instead of the holistic experience with AI
   - (3) Gaps in models used

- Recommendations for Future Work
   - (1) Human-centered analysis to define the design space of AI assistance elements
   - (2) Extend the design space and studies beyond decision trials
   - (3) Task-driven studies to complement feature-driven studies



- Current trends in how surveyed studies evaluate human-AI decision-making:
  1. Diverse evaluation focuses. 
  2. A focus on efficacy when evaluating decision tasks, but efficiency and subjective satisfaction are also useful indicators.
  3. Focuses on understanding, trust, system satisfaction, and fairness with regard to AI
  4. A lack of common measurements.

- gaps in the field
  - A focus on decision efficacy (i.e., performance), and less emphasis on efficiency and user satisfaction.
  The use of subjective versus objective measurements needs to be better understood and regulated.
  - Home-grown measurements, especially subjective survey items, are often used.
  - Variance in the coverage of measurements.

- A few core recommendations for future work emerged:
  - Building on each other’s work.
  - Developing common frameworks for human-AI decision-making.
  - Bridging AI and HCI communities to mutually shape human-AI decision-making.

### Limitations and Assumptions of this paper
- The survey may not cover all existing empirical studies due to the selection criteria 
- Findings are limited to the studies reviewed, i.e. the 100 papers. 

### Conclusion
- The survey serves as a foundational step towards establishing a science of human-AI decision-making 
- calling for rigorous scientific frameworks to understand and improve how humans interact with AI systems in decision-making processes.

### Reference
- Scharowski, N., Benk, M., Kühne, S. J., Wettstein, L., & Brühlmann, F. (2023, June). Certification labels for trustworthy ai: Insights from an empirical mixed-method study. In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (pp. 248-260).
